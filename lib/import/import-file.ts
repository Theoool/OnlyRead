/**
 * æ–‡ä»¶å¯¼å…¥å¤„ç†å™¨ - ä¼˜åŒ–ç‰ˆ
 * 
 * æ”¹è¿›ç‚¹:
 * 1. ä½¿ç”¨ArticleCreatorç»Ÿä¸€åˆ›å»ºé€»è¾‘
 * 2. ä½¿ç”¨IndexingSchedulerå¼‚æ­¥ç´¢å¼•
 * 3. ä½¿ç”¨ContentProcessorå¤„ç†å†…å®¹ï¼ˆä¿ç•™å›¾ç‰‡å’Œé“¾æ¥ï¼‰
 * 4. é™ä½åµŒå¥—å¤æ‚åº¦
 * 5. æ”¹è¿›é”™è¯¯å¤„ç†
 * 6. æ·»åŠ äº‹åŠ¡ä¿æŠ¤
 * 7. ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢
 * 8. æ·»åŠ è¿›åº¦åé¦ˆ
 * 9. å®ç°å¹¶è¡Œå¤„ç†
 * 10. æ·»åŠ é‡è¯•æœºåˆ¶
 */

import { prisma } from '@/lib/infrastructure/database/prisma';
import { getServiceClient } from '@/lib/supabase/server';
import { ForbiddenError } from '@/lib/infrastructure/error';
import { revalidatePath } from 'next/cache';
import { processFileOnServer } from '@/lib/server/file-processor-server';
import { ArticleCreator } from './article-creator';
import { IndexingScheduler } from './indexing-scheduler';
import type { ProcessedBook } from '@/lib/integration/file-processor-bridge';
import { ContentProcessor } from './content-processor';

export interface ImportFileParams {
  userId: string;
  filePath: string;
  originalName: string;
  fileType?: string;
  strictMode?: boolean; // ä¸¥æ ¼æ¨¡å¼ï¼šä»»ä½•å¤±è´¥éƒ½å›æ»š
  onProgress?: (progress: ImportProgress) => void; // è¿›åº¦å›è°ƒ
}

export interface ImportFileResult {
  success: boolean;
  data: {
    collection: any;
    articlesCount: number;
    totalChapters: number;
    jobId?: string;
    errors?: any[];
    warnings?: any[];
    metadata?: any;
    partialSuccess?: boolean; // æ˜¯å¦éƒ¨åˆ†æˆåŠŸ
  };
}

export interface ImportProgress {
  stage: 'download' | 'parse' | 'create_collection' | 'create_articles' | 'update_stats' | 'schedule_indexing' | 'cleanup';
  progress: number; // 0-100
  message: string;
  details?: any;
}

// é‡è¯•é…ç½®
const RETRY_CONFIG = {
  maxRetries: 3,
  retryDelay: 1000, // 1ç§’
  retryableErrors: ['ECONNRESET', 'ETIMEDOUT', 'ENOTFOUND'],
};

/**
 * ä¸ºç”¨æˆ·å¯¼å…¥æ–‡ä»¶ï¼ˆä¼˜åŒ–ç‰ˆï¼‰
 */
export async function importFileForUser(params: ImportFileParams): Promise<ImportFileResult> {
  const { userId, filePath, originalName, strictMode = false, onProgress } = params;

  console.log('[ImportFile] Starting file import', { userId, filePath, originalName, strictMode });

  const reportProgress = (stage: ImportProgress['stage'], progress: number, message: string, details?: any) => {
    onProgress?.({ stage, progress, message, details });
    console.log(`[ImportFile] ${stage}: ${progress}% - ${message}`);
  };

  try {
    // 1. éªŒè¯å‚æ•°
    reportProgress('download', 0, 'éªŒè¯å‚æ•°...');
    validateParams(filePath, originalName, userId);

    // 2. ä¸‹è½½æ–‡ä»¶ï¼ˆå¸¦é‡è¯•ï¼‰
    reportProgress('download', 10, 'ä¸‹è½½æ–‡ä»¶...');
    const buffer = await retryOperation(
      () => downloadFile(filePath),
      'ä¸‹è½½æ–‡ä»¶'
    );
    reportProgress('download', 30, `æ–‡ä»¶ä¸‹è½½å®Œæˆ (${buffer.length} å­—èŠ‚)`);

    // 3. è§£ææ–‡ä»¶ï¼ˆå¸¦é‡è¯•ï¼‰
    reportProgress('parse', 40, 'è§£ææ–‡ä»¶å†…å®¹...');
    const parsedBook = await retryOperation(
      () => parseFile(buffer, originalName),
      'è§£ææ–‡ä»¶'
    );
    reportProgress('parse', 60, `è§£æå®Œæˆï¼Œå…± ${parsedBook.chapters.length} ç« èŠ‚`);

    // 4. ä½¿ç”¨äº‹åŠ¡åˆ›å»ºæ•°æ®ï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼‰
    reportProgress('create_collection', 65, 'åˆ›å»ºé›†åˆå’Œæ–‡ç« ...');
    const { collection, articles, errors, warnings, totalWords, estimatedReadTime } = 
      await createCollectionAndArticlesInTransaction(parsedBook, originalName, userId);

    reportProgress('create_articles', 80, `åˆ›å»ºå®Œæˆï¼š${articles.length}/${parsedBook.chapters.length} ç¯‡æ–‡ç« `);

    // 5. å¤„ç†å¤±è´¥æƒ…å†µ
    const successRate = articles.length / parsedBook.chapters.length;
    const partialSuccess = articles.length > 0 && articles.length < parsedBook.chapters.length;

    if (articles.length === 0) {
      throw new Error(
        `å¯¼å…¥å¤±è´¥ï¼šæ‰€æœ‰ç« èŠ‚éƒ½æ— æ³•åˆ›å»ºã€‚` +
        `æ€»ç« èŠ‚æ•°: ${parsedBook.chapters.length}, ` +
        `é”™è¯¯: ${errors.map(e => e.error).join('; ')}`
      );
    }

    if (strictMode && partialSuccess) {
      throw new Error(
        `ä¸¥æ ¼æ¨¡å¼ï¼šéƒ¨åˆ†ç« èŠ‚åˆ›å»ºå¤±è´¥ã€‚` +
        `æˆåŠŸ: ${articles.length}/${parsedBook.chapters.length}, ` +
        `å¤±è´¥: ${errors.length}`
      );
    }

    if (successRate < 0.5) {
      throw new Error(
        `å¯¼å…¥å¤±è´¥ï¼šæˆåŠŸç‡è¿‡ä½ (${(successRate * 100).toFixed(1)}%)ã€‚` +
        `æˆåŠŸ: ${articles.length}, å¤±è´¥: ${errors.length}`
      );
    }

    // 6. å¹¶è¡Œæ‰§è¡Œï¼šæ›´æ–°ç»Ÿè®¡ + è°ƒåº¦ç´¢å¼• + æ¸…ç†æ–‡ä»¶
    reportProgress('update_stats', 85, 'æ›´æ–°ç»Ÿè®¡ä¿¡æ¯...');
    
    const [jobId, cleanupWarnings] = await Promise.allSettled([
      scheduleIndexing(articles, userId),
      cleanupFile(filePath),
    ]).then(results => [
      results[0].status === 'fulfilled' ? results[0].value : undefined,
      results[1].status === 'fulfilled' ? results[1].value : [],
    ]);

    reportProgress('schedule_indexing', 95, 'ç´¢å¼•ä»»åŠ¡å·²è°ƒåº¦');

    // 7. åˆ·æ–°ç¼“å­˜
    reportProgress('cleanup', 98, 'æ¸…ç†ç¼“å­˜...');
    revalidatePath('/');
    revalidatePath('/collections');

    reportProgress('cleanup', 100, 'å¯¼å…¥å®Œæˆï¼');

    console.log('[ImportFile] File import completed', {
      collectionId: collection.id,
      articlesCount: articles.length,
      totalChapters: parsedBook.chapters.length,
      successRate: `${(successRate * 100).toFixed(1)}%`,
      jobId,
      partialSuccess,
    });

    // 8. è¿”å›ç»“æœ
    return {
      success: true,
      data: {
        collection,
        articlesCount: articles.length,
        totalChapters: parsedBook.chapters.length,
        jobId,
        errors: errors.length > 0 ? errors : undefined,
        warnings: [...warnings, ...cleanupWarnings, ...(parsedBook.failedChapters || [])],
        metadata: {
          ...parsedBook.metadata,
          processingArchitecture: parsedBook.metadata?.processedBy || 'unknown',
          performance: parsedBook.performance,
          totalWords,
          estimatedReadTime,
          successRate: `${(successRate * 100).toFixed(1)}%`,
        },
        partialSuccess,
      },
    };
  } catch (error) {
    const errorMessage = error instanceof Error ? error.message : String(error);
    console.error('[ImportFile] Import failed:', errorMessage);
    reportProgress('cleanup', 0, `å¯¼å…¥å¤±è´¥: ${errorMessage}`);
    throw error;
  }
}

/**
 * éªŒè¯å‚æ•°
 */
function validateParams(filePath: string, originalName: string, userId: string): void {
  if (!filePath || !originalName) {
    throw new Error('ç¼ºå°‘å¿…éœ€å‚æ•°: filePath æˆ– originalName');
  }

  if (!filePath.startsWith(`${userId}/`)) {
    throw new ForbiddenError('æ— æ•ˆçš„æ–‡ä»¶è·¯å¾„ï¼šè·¯å¾„å¿…é¡»ä»¥ç”¨æˆ·IDå¼€å¤´');
  }

  // éªŒè¯æ–‡ä»¶ç±»å‹
  const supportedExtensions = ['.epub', '.pdf', '.txt', '.md'];
  const ext = originalName.toLowerCase().match(/\.[^.]+$/)?.[0];
  if (!ext || !supportedExtensions.includes(ext)) {
    throw new Error(`ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: ${ext}ã€‚æ”¯æŒçš„ç±»å‹: ${supportedExtensions.join(', ')}`);
  }
}

/**
 * é‡è¯•æ“ä½œï¼ˆé€šç”¨é‡è¯•æœºåˆ¶ï¼‰
 */
async function retryOperation<T>(
  operation: () => Promise<T>,
  operationName: string,
  retries = RETRY_CONFIG.maxRetries
): Promise<T> {
  let lastError: Error | undefined;

  for (let attempt = 1; attempt <= retries; attempt++) {
    try {
      return await operation();
    } catch (error) {
      lastError = error instanceof Error ? error : new Error(String(error));
      
      const isRetryable = RETRY_CONFIG.retryableErrors.some(
        errCode => lastError!.message.includes(errCode)
      );

      if (attempt < retries && isRetryable) {
        const delay = RETRY_CONFIG.retryDelay * attempt;
        console.warn(
          `[ImportFile] ${operationName} å¤±è´¥ (å°è¯• ${attempt}/${retries}), ` +
          `${delay}ms åé‡è¯•...`,
          lastError.message
        );
        await new Promise(resolve => setTimeout(resolve, delay));
      } else {
        break;
      }
    }
  }

  throw new Error(
    `${operationName} å¤±è´¥ (å·²é‡è¯• ${retries} æ¬¡): ${lastError?.message || 'æœªçŸ¥é”™è¯¯'}`
  );
}

/**
 * ä¸‹è½½æ–‡ä»¶
 */
async function downloadFile(filePath: string): Promise<Buffer> {
  console.log('[ImportFile] Downloading file from storage');

  const supabase = await getServiceClient();
  const { data: fileData, error: downloadError } = await supabase.storage
    .from('files')
    .download(filePath);

  if (downloadError || !fileData) {
    throw new Error(
      `æ–‡ä»¶ä¸‹è½½å¤±è´¥: ${downloadError?.message || 'æœªçŸ¥é”™è¯¯'}ã€‚` +
      `æ–‡ä»¶è·¯å¾„: ${filePath}`
    );
  }

  const buffer = Buffer.from(await fileData.arrayBuffer());
  console.log('[ImportFile] File downloaded', { 
    size: buffer.length,
    sizeKB: (buffer.length / 1024).toFixed(2) 
  });

  return buffer;
}

/**
 * è§£ææ–‡ä»¶
 */
async function parseFile(buffer: Buffer, originalName: string): Promise<ProcessedBook> {
  console.log('[ImportFile] Parsing file');

  const parsedBook = await processFileOnServer(buffer, originalName);

  if (!parsedBook.chapters || parsedBook.chapters.length === 0) {
    throw new Error(
      `æ–‡ä»¶è§£æå¤±è´¥ï¼šæœªæ‰¾åˆ°ä»»ä½•ç« èŠ‚ã€‚` +
      `æ–‡ä»¶å: ${originalName}, ` +
      `æ–‡ä»¶å¤§å°: ${buffer.length} å­—èŠ‚`
    );
  }

  // éªŒè¯ç« èŠ‚å†…å®¹
  const validChapters = parsedBook.chapters.filter(ch => ch.content && ch.content.trim().length > 0);
  if (validChapters.length === 0) {
    throw new Error(
      `æ–‡ä»¶è§£æå¤±è´¥ï¼šæ‰€æœ‰ç« èŠ‚å†…å®¹ä¸ºç©ºã€‚` +
      `æ€»ç« èŠ‚æ•°: ${parsedBook.chapters.length}`
    );
  }

  console.log('[ImportFile] File parsed', {
    title: parsedBook.title,
    chaptersCount: parsedBook.chapters.length,
    validChapters: validChapters.length,
    totalSize: parsedBook.chapters.reduce((sum, ch) => sum + (ch.content?.length || 0), 0),
  });

  return parsedBook;
}

/**
 * ä½¿ç”¨äº‹åŠ¡åˆ›å»º Collection å’Œ Articlesï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼‰
 */
async function createCollectionAndArticlesInTransaction(
  parsedBook: ProcessedBook,
  originalName: string,
  userId: string
): Promise<{
  collection: any;
  articles: any[];
  errors: Array<{ index: number; error: string }>;
  warnings: string[];
  totalWords: number;
  estimatedReadTime: number;
}> {
  console.log('[ImportFile] Starting transaction for collection and articles');

  // é¢„è®¡ç®—ç»Ÿè®¡æ•°æ®ï¼ˆé¿å…é‡å¤æŸ¥è¯¢ï¼‰
  const totalWords = parsedBook.chapters.reduce((sum: number, ch: any) => 
    sum + (ch.content?.length || 0), 0
  );
  const estimatedReadTime = Math.ceil(totalWords / 300);

  const isEpub = originalName.toLowerCase().endsWith('.epub');
  const safeTitle = ContentProcessor.sanitizeString(
    parsedBook.title || originalName || 'UNKğŸ“•'
  );
  const safeDesc = ContentProcessor.sanitizeString(
    parsedBook.description || parsedBook.metadata?.description || ''
  );

  // é¢„å¤„ç†æ‰€æœ‰ç« èŠ‚æ•°æ®
  const articlesData = parsedBook.chapters.map((chapter: any, index: number) => {
    const content = chapter.content || '';
    const totalBlocks = Math.max(1, Math.ceil(content.length / 500));
    
    return {
      title: ContentProcessor.sanitizeString(chapter.title || `ç¬¬ ${index + 1} ç« `),
      content,
      order: index,
      type: 'markdown' as const,
      domain: null,
      url: null,
      summary: chapter.summary || null,
      totalBlocks,
    };
  });

  // ä½¿ç”¨äº‹åŠ¡æ‰§è¡Œæ‰€æœ‰æ•°æ®åº“æ“ä½œ
  const result = await prisma.$transaction(async (tx) => {
    // 1. åˆ›å»º Collection
    const collection = await tx.collection.create({
      data: {
        title: safeTitle,
        description: safeDesc,
        type: isEpub ? 'BOOK' : 'SERIES',
        userId,
        author: parsedBook.metadata?.author || null,
        language: parsedBook.metadata?.language || 'zh-CN',
        isbn: parsedBook.metadata?.isbn || null,
        totalChapters: parsedBook.chapters.length,
        totalWords: BigInt(totalWords),
        estimatedReadTime,
        readingProgress: 0,
        completedChapters: 0,
      },
    });

    console.log('[ImportFile] Collection created in transaction', { 
      collectionId: collection.id 
    });

    // 2. æ‰¹é‡åˆ›å»º Articlesï¼ˆä½¿ç”¨ ContentProcessorï¼‰
    const articles: any[] = [];
    const errors: Array<{ index: number; error: string }> = [];
    const warnings: string[] = [];

    for (let i = 0; i < articlesData.length; i++) {
      const data = articlesData[i];
      
      try {
        // å¤„ç†å†…å®¹
        const processed = ContentProcessor.process(data.content, {
          preserveImages: true,
          preserveLinks: true,
        });
        warnings.push(...processed.warnings.map(w => `[ç« èŠ‚ ${i + 1}] ${w}`));

        // åˆ›å»ºæ–‡ç« å’Œæ–‡ç« ä½“
        const article = await tx.article.create({
          data: {
            title: data.title,
            url: null,
            domain: null,
            userId,
            collectionId: collection.id,
            order: data.order,
            type: data.type,
            summary: data.summary,
            totalBlocks: processed.metadata.totalBlocks,
            totalReadingTime: processed.metadata.estimatedReadingTime,
            progress: 0,
            currentPosition: 0,
            completedBlocks: 0,
            body: {
              create: {
                content: processed.content,
                markdown: processed.content,
              },
            },
          },
          include: {
            body: true,
          },
        });

        articles.push(article);
      } catch (err) {
        const errorMsg = err instanceof Error ? err.message : String(err);
        console.error(`[ImportFile] Failed to create article ${i}:`, errorMsg);
        errors.push({
          index: i,
          error: `ç« èŠ‚ "${data.title}" åˆ›å»ºå¤±è´¥: ${errorMsg}`,
        });
      }
    }

    // 3. æ›´æ–°ç”¨æˆ·ç»Ÿè®¡ï¼ˆåœ¨åŒä¸€äº‹åŠ¡ä¸­ï¼‰
    if (articles.length > 0) {
      await tx.readingStats.upsert({
        where: { userId },
        create: {
          userId,
          totalArticles: articles.length,
          lastReadDate: new Date(),
        },
        update: {
          totalArticles: {
            increment: articles.length,
          },
          updatedAt: new Date(),
        },
      });
    }

    console.log('[ImportFile] Transaction completed', {
      collectionId: collection.id,
      articlesCreated: articles.length,
      articlesFailed: errors.length,
    });

    return { collection, articles, errors, warnings };
  }, {
    maxWait: 30000, // æœ€å¤šç­‰å¾…30ç§’
    timeout: 60000, // è¶…æ—¶60ç§’
  });

  return {
    ...result,
    totalWords,
    estimatedReadTime,
  };
}

/**
 * è°ƒåº¦ç´¢å¼•ä»»åŠ¡
 */
async function scheduleIndexing(articles: any[], userId: string): Promise<string | undefined> {
  if (articles.length === 0) {
    return undefined;
  }

  console.log('[ImportFile] Scheduling indexing');

  try {
    const articleIds = articles.map((a) => a.id);
    const jobId = await IndexingScheduler.schedule(articleIds, userId, 'FILE');

    console.log('[ImportFile] Indexing scheduled', { 
      jobId, 
      articlesCount: articleIds.length 
    });

    return jobId;
  } catch (err) {
    console.error('[ImportFile] Failed to schedule indexing:', err);
    // ä¸æŠ›å‡ºé”™è¯¯ï¼Œç´¢å¼•å¤±è´¥ä¸åº”è¯¥å½±å“å¯¼å…¥
    return undefined;
  }
}

/**
 * æ¸…ç†æ–‡ä»¶
 */
async function cleanupFile(filePath: string): Promise<string[]> {
  const warnings: string[] = [];

  try {
    const supabase = await getServiceClient();
    const { error } = await supabase.storage.from('files').remove([filePath]);
    
    if (error) {
      throw error;
    }
    
    console.log('[ImportFile] File cleaned up successfully');
  } catch (err) {
    const errorMsg = err instanceof Error ? err.message : String(err);
    console.warn('[ImportFile] Failed to cleanup file:', errorMsg);
    warnings.push(`æ–‡ä»¶æ¸…ç†å¤±è´¥: ${errorMsg}`);
  }

  return warnings;
}

// ä»¥ä¸‹å‡½æ•°å·²è¢«äº‹åŠ¡ç‰ˆæœ¬æ›¿ä»£ï¼Œä¿ç•™ç”¨äºå‘åå…¼å®¹
// å·²åºŸå¼ƒï¼šcreateCollection, createArticles, updateUserStats, updateCollectionStats
